{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fed23e6",
   "metadata": {},
   "source": [
    "## Spark Dataframe\n",
    "We can manually create a PySpark DataFrame using toDF() and createDataFrame() methods, both these function takes different signatures in order to create DataFrame from existing RDD, list, and DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa90735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"testApp\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca40b57a",
   "metadata": {},
   "source": [
    "#### Create DataFrame from RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede54a73",
   "metadata": {},
   "source": [
    "|S.No.| Item     |  Input           | Command         | Output| Comment|\n",
    "|:----|:-------------|:------------------:|:-------------:|:-----:|:------|\n",
    "|  1  | Create DataFrame from RDD         |RDD| `rdd.toDF() `     | DF | |\n",
    "|  2  | Create DataFrame from RDD with columns         |RDD| `rdd.toDF(col_list)`     | DF | |\n",
    "|  3  | Create DataFrame from RDD using createDataFrame         |RDD| `spark.createDataFrame(rdd)`     | DF | |\n",
    "|  4  | Create DataFrame from RDD using createDataFrame with columns         |RDD| `spark.createDataFrame(rdd, schema=cols)`     | DF | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3749fe4f",
   "metadata": {},
   "source": [
    "##### Using toDF() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78130f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ((1, 2, 3),(4, 5, 6),(7, 8, 9))\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "type(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c6d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df = rdd.toDF()\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d38a7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "| _1| _2| _3|\n",
      "+---+---+---+\n",
      "|  1|  2|  3|\n",
      "|  4|  5|  6|\n",
      "|  7|  8|  9|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925e1155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      " |-- _3: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4254cc",
   "metadata": {},
   "source": [
    "##### With columns also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c5afc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|COL1|COL2|COL3|\n",
      "+----+----+----+\n",
      "|   1|   2|   3|\n",
      "|   4|   5|   6|\n",
      "|   7|   8|   9|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = [\"COL1\",\"COL2\",\"COL3\"]\n",
    "df = rdd.toDF(cols)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc96b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COL1: long (nullable = true)\n",
      " |-- COL2: long (nullable = true)\n",
      " |-- COL3: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41ef99",
   "metadata": {},
   "source": [
    "##### Using createDataFrame()\n",
    "spark.createDataFrame(rdd).toDF(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6848267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1adbc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "| _1| _2| _3|\n",
      "+---+---+---+\n",
      "|  1|  2|  3|\n",
      "|  4|  5|  6|\n",
      "|  7|  8|  9|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ba05c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      " |-- _3: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7fe442",
   "metadata": {},
   "source": [
    "##### with columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7987be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd, schema=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d28338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|COL1|COL2|COL3|\n",
      "+----+----+----+\n",
      "|   1|   2|   3|\n",
      "|   4|   5|   6|\n",
      "|   7|   8|   9|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bef2e284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COL1: long (nullable = true)\n",
      " |-- COL2: long (nullable = true)\n",
      " |-- COL3: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ea5631",
   "metadata": {},
   "source": [
    "#### Create DataFrame from List/Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a111ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1,\"John\",\"25\"), (2,\"Sam\",\"26\"), (3,\"Saul\", \"30\"),(4,\"Jorah\", \"30\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c77b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "288e66d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| _1|   _2| _3|\n",
      "+---+-----+---+\n",
      "|  1| John| 25|\n",
      "|  2|  Sam| 26|\n",
      "|  3| Saul| 30|\n",
      "|  4|Jorah| 30|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b4d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"id\",\"name\",\"age\"]\n",
    "df = spark.createDataFrame(data,schema=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "252b3fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| id| name|age|\n",
      "+---+-----+---+\n",
      "|  1| John| 25|\n",
      "|  2|  Sam| 26|\n",
      "|  3| Saul| 30|\n",
      "|  4|Jorah| 30|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7f585",
   "metadata": {},
   "source": [
    "#### Create DataFrame with the Row type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "659214d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0909fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[\n",
    "    Row(ID=1,NAME=\"John\",AGE=20),\n",
    "    Row(ID=2,NAME=\"Sam\",AGE=25)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a89e2263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(AGE=20, ID=1, NAME='John'), Row(AGE=25, ID=2, NAME='Sam')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e6825ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64d6db5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|AGE| ID|NAME|\n",
      "+---+---+----+\n",
      "| 20|  1|John|\n",
      "| 25|  2| Sam|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "459b30c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AGE: long (nullable = true)\n",
      " |-- ID: long (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c1ee6",
   "metadata": {},
   "source": [
    "#### Create DataFrame using Namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0167e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10c99b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust = namedtuple(\"CUSTOMER\",[\"CUSTOMER_ID\",\"CUSTOMER_NAME\",\"CUSTOMER_ADDR\",\"CUSTOMER_EMAIL\",\"CUSTOMER_PHONE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41fe393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [cust(1,\"James\",\"639 Main St\",\"james@comapny.com\",\"504-845-1427\"),\n",
    "        cust(2,\"John\",\"#45 Main St\",\"john@comapny.com\",\"804-895-1427\"),\n",
    "        cust(3,\"Sam\",\"34 Center St\",\"sam@comapny.com\",\"704-895-1427\"),\n",
    "        cust(4,\"John\",\"322 New Horizon\",\"john@comapny.com\",\"604-895-1427\")\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2cc96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "965d448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------+-----------------+--------------+\n",
      "|CUSTOMER_ID|CUSTOMER_NAME|  CUSTOMER_ADDR|   CUSTOMER_EMAIL|CUSTOMER_PHONE|\n",
      "+-----------+-------------+---------------+-----------------+--------------+\n",
      "|          1|        James|    639 Main St|james@comapny.com|  504-845-1427|\n",
      "|          2|         John|    #45 Main St| john@comapny.com|  804-895-1427|\n",
      "|          3|          Sam|   34 Center St|  sam@comapny.com|  704-895-1427|\n",
      "|          4|         John|322 New Horizon| john@comapny.com|  604-895-1427|\n",
      "+-----------+-------------+---------------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "183d49fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CUSTOMER_ID: long (nullable = true)\n",
      " |-- CUSTOMER_NAME: string (nullable = true)\n",
      " |-- CUSTOMER_ADDR: string (nullable = true)\n",
      " |-- CUSTOMER_EMAIL: string (nullable = true)\n",
      " |-- CUSTOMER_PHONE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab7febd",
   "metadata": {},
   "source": [
    "#### Create DataFrame with StructType Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ba81a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,IntegerType,StringType,FloatType\n",
    "\n",
    "schema =StructType([\n",
    "            StructField(\"id\", IntegerType(), True),\n",
    "            StructField(\"name\", StringType(), True),\n",
    "        ])\n",
    "\n",
    "df = spark.createDataFrame([(1, \"john\"),(2, \"sam\"),],schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55c4dd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|name|\n",
      "+---+----+\n",
      "|  1|john|\n",
      "|  2| sam|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dad5aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3346e1",
   "metadata": {},
   "source": [
    "##### Creating Empty Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ebdd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = [\n",
    "    StructField(\"COL1\", FloatType(), True),\n",
    "    StructField(\"COL2\", StringType(), True),\n",
    "]\n",
    "schema = StructType(field)\n",
    "empty_df = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd7580a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|COL1|COL2|\n",
      "+----+----+\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empty_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39b1a4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COL1: float (nullable = true)\n",
      " |-- COL2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empty_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd72877",
   "metadata": {},
   "source": [
    "#### Create a sample single-column Spark DataFrame in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2086933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([1,2,3,4,5], \"integer\").toDF(\"numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb76d072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|numbers|\n",
      "+-------+\n",
      "|      1|\n",
      "|      2|\n",
      "|      3|\n",
      "|      4|\n",
      "|      5|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06a3b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([1,2,3,4,5], IntegerType()).toDF(\"numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6de599e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|numbers|\n",
      "+-------+\n",
      "|      1|\n",
      "|      2|\n",
      "|      3|\n",
      "|      4|\n",
      "|      5|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "687cccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\"x\",\"y\",\"z\"], StringType()).toDF(\"char_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04808f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|char_data|\n",
      "+---------+\n",
      "|        x|\n",
      "|        y|\n",
      "|        z|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd9f8e6",
   "metadata": {},
   "source": [
    "With name elements should be tuples and schema as sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63032afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(1, ), (2, ), (2,  )], [\"num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cdcdc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|num|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  2|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553af25e",
   "metadata": {},
   "source": [
    "Coverting RDD into tuple form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b714bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRdd = spark.sparkContext.parallelize([1.0,2.0,3.0,4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aaaf3b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = myRdd.map(lambda x: (x, )).toDF([\"COL1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31c00c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|COL1|\n",
      "+----+\n",
      "| 1.0|\n",
      "| 2.0|\n",
      "| 3.0|\n",
      "| 4.0|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280189c6",
   "metadata": {},
   "source": [
    "Otherway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6f03913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "row = Row(\"val\") # Or some other column name\n",
    "df_other = myRdd.map(row).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "077114df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|val|\n",
      "+---+\n",
      "|1.0|\n",
      "|2.0|\n",
      "|3.0|\n",
      "|4.0|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_other.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
