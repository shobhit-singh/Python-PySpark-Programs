# PySpark-Programs

## Spark RDD
RDD Basics: [link](https://github.com/shobhit-singh/Python-PySpark-Programs/blob/master/PySpark/rdd/Working-with-RDDs.ipynb) <br>
RDD Partitions Details: [link](https://github.com/shobhit-singh/Python-PySpark-Programs/blob/master/PySpark/rdd/getFilePartitionsDetails.py) <br>
Skip Headers RDD using `rdd.zipWithIndex()`: [link](https://github.com/shobhit-singh/Python-PySpark-Programs/blob/master/PySpark/rdd/zipWithIndex_SkipHeaders_RDD.ipynb) <br>
## Spark Dataframe
Create Dataframe row sha2: [link](https://github.com/shobhit-singh/Python-PySpark-Programs/blob/master/PySpark/dataframes/createDataframe_row_sha.ipynb) <br>
Spark Dataframe (`toDF()` & `createDataFrame()`): [link](https://github.com/shobhit-singh/Python-PySpark-Programs/blob/master/PySpark/dataframes/pySpark_dataframes.ipynb) <br>
Create Dataframe using namedtuple: [link](https://github.com/shobhit-singh/Python-PySpark-Programs/blob/master/PySpark/dataframes/namedTuple.ipynb) <br>
Dealing with timestamps: [link](https://github.com/shobhit-singh/Python-PySpark-Programs/blob/master/PySpark/dataframes/timestampsData.ipynb) <br>
<br>
Exploring Broadcast Join: [link](https://github.com/shobhit-singh/Python-PySpark-Programs/blob/master/PySpark/dataframes/broadcastJoin.ipynb) <br>
