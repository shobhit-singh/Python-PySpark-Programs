{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d427af66",
   "metadata": {},
   "source": [
    "#### Skip headers in RDD using zipWithIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d38d8bf",
   "metadata": {},
   "source": [
    "In this example we want to skip the unwanted headers in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a254b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: XYZ\n",
      "Craeted On:1/1/2010\n",
      "\n",
      "\n",
      "COL1|COL2\n",
      "D1|D2\n",
      "D3|D4\n",
      "D5|D6"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "hdfs dfs -cat tab_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784a5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"ShobhitApp\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c87dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile(\"/user/itv000197/tab_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b402098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_withIndex = rdd.zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14dc813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = rdd_withIndex.filter(lambda x: x[1] > 4).map(lambda x: x[0]).map(lambda x: x.split(\"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2603bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "row = Row(\"COL1\",\"COL2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865b8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_data.map(lambda x: row(x[0],x[1])).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d57188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|COL1|COL2|\n",
      "+----+----+\n",
      "|  D1|  D2|\n",
      "|  D3|  D4|\n",
      "|  D5|  D6|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
