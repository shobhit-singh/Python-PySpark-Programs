{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1629d7",
   "metadata": {},
   "source": [
    "# Resilient Distributed Dataset (RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf3f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"ShobhitApp\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f5bf20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78278eb3",
   "metadata": {},
   "source": [
    "#### Create RDD using sparkContext.parallelize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4398a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ((1, 2, 3),(4, 5, 6),(7, 8, 9))\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20f371e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c961a4",
   "metadata": {},
   "source": [
    "#### Create RDD using sparkContext.textFile()\n",
    "Using this method we can read a file into RDD. Compressed/Uncompressed, directories, or glob patterns (file patterns with wildcards) also.\n",
    "syntax: sc.textFile(name, minPartitions=None, use_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ce7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile(\"/user/itv000197/tab_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74fdc957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2b3eb0",
   "metadata": {},
   "source": [
    "#### Create RDD using sparkContext.wholeTextFiles()\n",
    "The method allow you to read a directory containing multiple files. Each file is represented as a record consisting of a key containing the filename and a value containing the contents of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eede0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.wholeTextFiles(\"/user/itv000197/inputfile/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f313c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hdfs://m01.itversity.com:9000/user/itv000197/inputfile/part-00000',\n",
       "  'Salman Rushide,Grimus:Shame:Fury\\nThomas Otway,Don Carlos:The Orphan\\n'),\n",
       " ('hdfs://m01.itversity.com:9000/user/itv000197/inputfile/part-00001',\n",
       "  'Ben Jonson,Volpone:Epicene\\nJohn Milton,Arcades:Comus\\n')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b13f9bc",
   "metadata": {},
   "source": [
    "#### Get Partition Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98f5b973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca8cf24",
   "metadata": {},
   "source": [
    "#### Actions:\n",
    "\n",
    "| Syntax      | Description | Return Type    |\n",
    "| :---        |    :----   |          ---: |\n",
    "| .collect()      | Action on an RDD returns a list of all the elements of the RDD       | List   |\n",
    "| .count()   | action on an RDD is an operation that returns the number of elements of our RDD        |      |\n",
    "| .first() |action on an RDD returns the first element from our RDD||\n",
    "|.take(n)|action on an RDD returns n number of elements from the RDD||\n",
    "|.saveAsTextFile()|Action is used to serve the resultant RDD as a text file||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcea96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile(\"/user/itv000197/authors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eadb7c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salman Rushide,Grimus:Shame:Fury',\n",
       " 'Thomas Otway,Don Carlos:The Orphan',\n",
       " 'Ben Jonson,Volpone:Epicene',\n",
       " 'John Milton,Arcades:Comus']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df9e3db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salman Rushide,Grimus:Shame:Fury']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "122294de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salman Rushide,Grimus:Shame:Fury'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06275eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1725921",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.saveAsTextFile(\"/user/itv000197/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa7019ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   3 itv000197 supergroup          0 2022-02-26 07:32 output/_SUCCESS\n",
      "-rw-r--r--   3 itv000197 supergroup         68 2022-02-26 07:32 output/part-00000\n",
      "-rw-r--r--   3 itv000197 supergroup         53 2022-02-26 07:32 output/part-00001\n"
     ]
    }
   ],
   "source": [
    " %%sh\n",
    "hdfs dfs -ls output/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e949b",
   "metadata": {},
   "source": [
    "#### Create Empy RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72f9ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyRdd = spark.sparkContext.emptyRDD() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd789c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(emptyRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d1a0759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emptyRdd.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
